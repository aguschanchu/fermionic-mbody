{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fbd68f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import openfermion as of\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "from openfermion.utils import commutator, count_qubits, hermitian_conjugated\n",
    "import functools\n",
    "import concurrent.futures\n",
    "from numba import njit\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "import sparse\n",
    "import itertools\n",
    "import linecache\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import sympy\n",
    "\n",
    "# Generación de base\n",
    "class fixed_basis:\n",
    "    @staticmethod\n",
    "    def int_to_bin(k, d):\n",
    "        return np.base_repr(k, 2).zfill(d)[::-1]  \n",
    "\n",
    "    @staticmethod\n",
    "    def bin_to_op(b):\n",
    "        tups = [(i, 1) for i, k in list(enumerate(list(b))) if k == '1']\n",
    "        return of.FermionOperator(tups)\n",
    "\n",
    "    def idx_to_repr(self, idx):\n",
    "        return self.canonicals[idx]\n",
    "\n",
    "    def opr_to_idx(self, opr):\n",
    "        for i in range(self.size): # Evitar esto ordenando opr\n",
    "            if self.base[i] == opr:\n",
    "                return i\n",
    "                \n",
    "    def op_to_idx(self, op):\n",
    "        # Normalizamos el orden\n",
    "        op = of.transforms.normal_ordered(op)\n",
    "        # Si es nulo, devolvemos None\n",
    "        if len(op.terms) == 0:\n",
    "            return None\n",
    "        act_lvls = lambda tt: [tpl[0] for tpl in next(iter(tt.terms.keys()))] # Consistente con lo anterior\n",
    "        act = act_lvls(op)\n",
    "        act_to_int = lambda x: np.sum([2**i for i in x])\n",
    "        search = np.where(self.num_ele == act_to_int(act))[0]\n",
    "        if search.size == 0:\n",
    "            return None\n",
    "        else:\n",
    "            return search[0]\n",
    "\n",
    "    # Calcula el valor medio a partir del indice del vector y el operador\n",
    "    def idx_mean_val(self, idx: int, op: of.FermionOperator):\n",
    "        vec = self.idx_to_repr(idx)\n",
    "        return np.real(np.transpose(vec) @ of.get_sparse_operator(op, n_qubits=self.d) @ vec)\n",
    "\n",
    "    # Calcula el valor medio a partir de un estado y el operador\n",
    "    def mean_val(self, vec, op):\n",
    "        idx = self.opr_to_idx(vec)\n",
    "        return self.idx_mean_val(idx, op)\n",
    "\n",
    "    # Calcula la contracción de un operador sobre dos estados dados\n",
    "    def idx_contraction(self, idx_1, idx_2, op):\n",
    "        rep = lambda x: self.idx_to_repr(x)\n",
    "        return np.real(np.transpose(rep(idx_1)) @ of.get_sparse_operator(op, n_qubits=self.d) @ rep(idx_2))\n",
    "\n",
    "    def create_basis(self, d, num = None, pairs = False):\n",
    "        basis = []\n",
    "        num_ele = []\n",
    "        for k in range(0,2**d):\n",
    "            b = self.int_to_bin(k, d)\n",
    "            if num != None:\n",
    "                if b.count('1') == num:\n",
    "                    if pairs:\n",
    "                        if np.all(b[::2] == b[1::2]):\n",
    "                            oper = self.bin_to_op(b)\n",
    "                            basis.append(oper)\n",
    "                            num_ele.append(k)\n",
    "                    else:\n",
    "                        oper = self.bin_to_op(b)\n",
    "                        basis.append(oper)\n",
    "                        num_ele.append(k)\n",
    "            else:\n",
    "                oper = self.bin_to_op(b)\n",
    "                basis.append(oper)\n",
    "        return basis, num_ele\n",
    "\n",
    "    def signs_gen(self, base):\n",
    "        signs = []\n",
    "        for op in base:\n",
    "            op_normal = of.transforms.normal_ordered(op)\n",
    "            if op_normal.terms:\n",
    "                coeff = next(iter(op_normal.terms.values()))\n",
    "                signs.append(np.sign(coeff))\n",
    "            else:\n",
    "                signs.append(0)\n",
    "        return np.array(signs)\n",
    "\n",
    "    def __init__(self, d, num = None, pairs = False, basis = None, num_ele = None):\n",
    "        self.d = d\n",
    "        self.num = num\n",
    "        self.m = num\n",
    "        # Si nos da la base, la levantamos (asumimos GC). Si no, la creamos\n",
    "        if basis is None:\n",
    "            self.base, self.num_ele = self.create_basis(d, num, pairs)\n",
    "            self.signs = self.signs_gen(self.base)\n",
    "        else:\n",
    "            self.base, self.num_ele = basis, num_ele\n",
    "            self.signs = self.signs_gen(basis)\n",
    "        self.size = len(self.base)\n",
    "        self.canonicals = np.eye(self.size)\n",
    "        self.pairs = pairs\n",
    "\n",
    "    @staticmethod\n",
    "    def cdc(i, j):\n",
    "        return of.FermionOperator(((i,1),(j,0)))\n",
    "\n",
    "    @staticmethod\n",
    "    def cc(i, j):\n",
    "        return of.FermionOperator(((i,0),(j,0)))\n",
    "\n",
    "    # Del indice, cuenta el número de partículas\n",
    "    def num_idx(self, idx):\n",
    "        b = self.int_to_bin(idx, basis.d)\n",
    "        return b.count('1')\n",
    "\n",
    "    # Calculo de rho1 (via directa, lento, y solo definido en la base por ahora)\n",
    "    def rho_1(self, op):\n",
    "        # Necesitamos un índice, es?\n",
    "        if type(op) != int:\n",
    "            op = self.opr_to_idx(op)\n",
    "        mat = np.zeros((self.d, self.d))\n",
    "        for i in range(self.d):\n",
    "            for j in range(self.d):\n",
    "                cdc = self.cdc(j, i)\n",
    "                mat[i,j] = self.idx_mean_val(op, cdc)\n",
    "        return mat\n",
    "\n",
    "# Calculo de generadores de rho1\n",
    "def rho_1_gen(basis):\n",
    "    # Vamos a crear un hipersparse de TF, almacenamos los valores acá\n",
    "    indices = []\n",
    "    values = []\n",
    "    shape = (basis.d, basis.d, basis.size, basis.size)\n",
    "    d = basis.d\n",
    "    for i in tqdm(range(0, d)):\n",
    "        for j in range(0, d):\n",
    "            # Generamos el operador\n",
    "            op = basis.cdc(j, i)\n",
    "            #print(op)\n",
    "            if basis.num == None:\n",
    "                mat = np.real(of.get_sparse_operator(op, n_qubits=d))\n",
    "            else:\n",
    "                mat = np.real(of.get_sparse_operator(op, n_qubits=d))[np.ix_(basis.num_ele, basis.num_ele)]\n",
    "            # Extraemos la información\n",
    "            n_r, n_c = mat.nonzero()\n",
    "            data = mat.data\n",
    "            for r, c, v in zip(n_r, n_c, data):\n",
    "                indices.append([i, j, r, c])\n",
    "                values.append(v)\n",
    "    indices_t = np.array(indices).T\n",
    "    s_t = sparse.COO(indices_t, values, shape=shape)\n",
    "    return s_t\n",
    "\n",
    "# Calculo de rho1 (via generadores) de un vector en la base canonica\n",
    "def rho_1(vect, rho_1_arrays):\n",
    "    if len(vect.shape) == 1: # vectores\n",
    "        return sparse.einsum('k,ijkl,l->ij', vect, rho_1_arrays, vect)\n",
    "    elif len(vect.shape) == 2: # mat densidad\n",
    "        return sparse.einsum('ijkl,kl->ij', rho_1_arrays, vect)\n",
    "    else: # mat densidad batcheadas\n",
    "        return sparse.einsum('bkl,ijkl->bij', vect, rho_1_arrays)\n",
    "\n",
    "# Calculo de indices de rho2kkbar\n",
    "def get_kkbar_indices(t_basis):\n",
    "    indices = []\n",
    "    for i, ind in enumerate(t_basis.num_ele):\n",
    "        v = t_basis.int_to_bin(ind, t_basis.d)\n",
    "        if np.all(v[::2] == v[1::2]):\n",
    "            indices.append(i)\n",
    "    return indices\n",
    "\n",
    "# Calculo de generadores de rho2\n",
    "def rho_2_gen(basis, t_basis, idx_list = []):\n",
    "    # Vamos a crear un hipersparse de TF, almacenamos los valores acá\n",
    "    d = basis.d\n",
    "    indices = []\n",
    "    values = []\n",
    "    if len(idx_list) == basis.m:\n",
    "        idx_list = idx_list\n",
    "    elif len(idx_list) == basis.m**4:\n",
    "        idx_list = np.unique(idx_list[:,0])\n",
    "    else:\n",
    "        idx_list = range(t_basis.size)\n",
    "    shape = (len(idx_list), len(idx_list), basis.size, basis.size)\n",
    "    for i, ii in tqdm(enumerate(idx_list), total=len(idx_list)):\n",
    "        for j, jj in enumerate(idx_list):\n",
    "            # Generamos el operador\n",
    "            op = t_basis.base[jj]*of.utils.hermitian_conjugated(t_basis.base[ii])\n",
    "            if basis.num == None:\n",
    "                mat = np.real(of.get_sparse_operator(op, n_qubits=d))\n",
    "            else:\n",
    "                mat = np.real(of.get_sparse_operator(op, n_qubits=d))[np.ix_(basis.num_ele, basis.num_ele)]\n",
    "            # Extraemos la información\n",
    "            n_r, n_c = mat.nonzero()\n",
    "            data = mat.data\n",
    "            for r, c, v in zip(n_r, n_c, data):\n",
    "                indices.append([i, j, r, c])\n",
    "                values.append(v)\n",
    "\n",
    "    indices_t = np.array(indices).T\n",
    "    s_t = sparse.COO(indices_t, values, shape=shape)\n",
    "    return s_t\n",
    "\n",
    "# rho_m_gen aux func\n",
    "def process_chunk(args):\n",
    "    chunk, m_basis, basis, d, it_set = args\n",
    "    indices = []\n",
    "    values = []\n",
    "    for ii in chunk:\n",
    "        for jj in it_set:\n",
    "            # Generate the operator\n",
    "            op = m_basis.base[jj] * of.utils.hermitian_conjugated(m_basis.base[ii])\n",
    "            mat = np.real(of.get_sparse_operator(op, n_qubits=d))[np.ix_(basis.num_ele, basis.num_ele)]\n",
    "            # Extract the information\n",
    "            n_r, n_c = mat.nonzero()\n",
    "            data = mat.data\n",
    "            for r, c, v in zip(n_r, n_c, data):\n",
    "                indices.append([ii, jj, r, c])\n",
    "                values.append(v)\n",
    "    return indices, values\n",
    "\n",
    "# Parallelized rho_m_gen\n",
    "def rho_m_gen(basis, m, num_workers=None):\n",
    "    if num_workers is None:\n",
    "        num_workers = cpu_count()  # Use all available CPUs by default\n",
    "    \n",
    "    indices = []\n",
    "    values = []\n",
    "    m_basis = fixed_basis(basis.d, num=m, pairs=basis.pairs)\n",
    "    shape = (m_basis.size, m_basis.size, basis.size, basis.size)\n",
    "\n",
    "    it_set = np.arange(m_basis.size)\n",
    "    chunks = np.array_split(it_set, num_workers)  # Split `it_set` into chunks for each worker\n",
    "\n",
    "    # Use multiprocessing Pool for parallel processing\n",
    "    with Pool(processes=num_workers) as pool:\n",
    "        # Pass arguments as tuples instead of using a lambda\n",
    "        results = list(\n",
    "            tqdm(\n",
    "                pool.imap(\n",
    "                    process_chunk, \n",
    "                    [(chunk, m_basis, basis, basis.d, it_set) for chunk in chunks]\n",
    "                ),\n",
    "                total=num_workers\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # Collect results from all processes\n",
    "    for indices_chunk, values_chunk in results:\n",
    "        indices.extend(indices_chunk)\n",
    "        values.extend(values_chunk)\n",
    "\n",
    "    # Construct the sparse array\n",
    "    indices_t = np.array(indices).T\n",
    "    s_t = sparse.COO(indices_t, values, shape=shape)\n",
    "    return s_t\n",
    "\n",
    "def rho_m(vect, rho_m_arrays):\n",
    "    if len(vect.shape) == 1:\n",
    "        return sparse.einsum('k,ijkl,l->ij', vect, rho_m_arrays, vect)\n",
    "    else:\n",
    "        return sparse.einsum('kl,ijlk->ij', vect, rho_m_arrays)\n",
    "\n",
    "# Calculo de rho2 (via generadores) de un estado en la base canonica\n",
    "def rho_2(vect, rho_2_arrays):\n",
    "    if len(vect.shape) == 1: # vectores SOLO RHO2 COMPLETA\n",
    "        return sparse.einsum('k,ijkl,l->ij', vect, rho_2_arrays, vect)\n",
    "    elif len(vect.shape) == 2: # mat densidad SOLO RHO2 COMPLETA\n",
    "        return sparse.einsum('ijkl,kl->ij', rho_2_arrays, vect)\n",
    "    else: # mat densidad batcheadas\n",
    "        return sparse.einsum('bkl,ijkl->bij', vect, rho_2_arrays)\n",
    "\n",
    "# Calculo de generadores de K (usado para quasiparticles) WIP SPARSE\n",
    "def k_gen(basis):\n",
    "    mat = np.zeros((basis.d, basis.d, basis.size, basis.size))\n",
    "    d = basis.d\n",
    "    for i in tqdm(range(0, d), total=d):\n",
    "        for j in range(0, d):\n",
    "            op = basis.cc(j, i)\n",
    "            if basis.num == None:\n",
    "                mat[i,j,::] = np.real(of.get_sparse_operator(op, n_qubits=d)).todense()\n",
    "            else:\n",
    "                mat[i,j,::] = np.real(of.get_sparse_operator(op, n_qubits=d)).todense()[np.ix_(basis.num_ele, basis.num_ele)]\n",
    "    return mat\n",
    "\n",
    "def k_vect(vect, k_gen):\n",
    "    return np.einsum('k,ijkl,l->ij', vect, k_gen, vect)\n",
    "\n",
    "# Calculo la matrix rho de cuasipartículas  WIP SPARSE\n",
    "def rho_qsp(vect, rho_1_arrays, k_arrays, rho1 = None):\n",
    "    if type(rho1) == None:\n",
    "        rho1 = rho_1(vect, rho_1_arrays)\n",
    "    k = k_vect(vect, k_arrays)\n",
    "\n",
    "    mat = np.block([[rho1, k], [-np.conjugate(k), np.eye(rho_1_arrays.shape[0])-np.conjugate(rho1)]])\n",
    "    return mat\n",
    "\n",
    "# Devuelve los indices que tienen a level ocupado\n",
    "def level_proy(d, level):\n",
    "    ids = []\n",
    "    for k in range(0,2**d):\n",
    "        b = fixed_basis.int_to_bin(k, d)\n",
    "        if b[level] == '1':\n",
    "            ids.append(k)\n",
    "    arr = np.zeros(2**d)\n",
    "    arr[np.array(ids)] = 1\n",
    "    return arr, ids\n",
    "\n",
    "def parity_levels(d):\n",
    "    rng = range(2**d)\n",
    "    binary_repr = np.vectorize(np.binary_repr)(rng)\n",
    "    ones_c = np.char.count(binary_repr, '1')\n",
    "    return np.array(rng)[ones_c % 2 == 1] # seleccionamos estados impares\n",
    "\n",
    "# Devuelve el vector postmedido\n",
    "def measure(basis, vect, level = 1):\n",
    "    l_arr, l_ids = level_proy(basis.d, level)\n",
    "    proy_v = vect * l_arr\n",
    "    comp_arr = np.logical_not(l_arr).astype(int)\n",
    "    comp_v = vect * comp_arr\n",
    "    norm = lambda v: v / np.linalg.norm(v)\n",
    "    return norm(proy_v), norm(comp_v)\n",
    "\n",
    "def entropy(rho, m):\n",
    "    S_fun = lambda rho: -1*np.trace(rho @ scipy.linalg.logm(rho)) / np.log(2)\n",
    "    ent = S_fun(rho) / (np.log2(scipy.special.binom(basis.d, m)))\n",
    "    return ent\n",
    "\n",
    "def build_csv_basis(csvf, d, m, split=True):\n",
    "    # En caso de split, solo toma la mitad de cada estado (UP). Para la reconstrucción, asumieremos que la secuencia es la siguiente\n",
    "    # UP1 X DOWN1, UP1 X DOWN2, ..., UP1 X DOWNN, UP2 X DOWN1... \n",
    "    # Construimos la base\n",
    "    ops = []\n",
    "    ops_int = []\n",
    "    d = d//2 if split else d\n",
    "    with open(csvf, 'r') as basis:\n",
    "        num_ele = []\n",
    "        # Contar los niveles\n",
    "        m_level = 0\n",
    "        # Creamos operadores\n",
    "        for l in basis.read().splitlines()[4:]:\n",
    "            natop = [int(x) for x in l.split(' ')[1:m//2+1 if split else None]] # Operador en forma de lista\n",
    "            #print(natop)\n",
    "            op = of.FermionOperator(([(i, 1) for i in natop]))\n",
    "            # Contamos niveles\n",
    "            m_level = max(m_level, *natop)\n",
    "            # Determinamos el índice\n",
    "            natop_to_int = lambda x: np.sum([2**i for i in x])\n",
    "            naint = natop_to_int(natop)\n",
    "            if naint not in ops_int:\n",
    "                num_ele.append(naint)\n",
    "                ops_int.append(naint)\n",
    "                ops.append(op)\n",
    "\n",
    "        # Determinamos m y d\n",
    "        num = len(natop)\n",
    "        #assert d == m_level+1\n",
    "    # Para ser consistente con el orden de fixed_basis, reordenamos\n",
    "    idx_set = np.argsort(num_ele)\n",
    "    return fixed_basis(d, num = num, pairs = False, basis = np.array(ops)[idx_set], num_ele=np.array(num_ele)[idx_set]), idx_set\n",
    "\n",
    "    # Al igual que rho_2_gen, genera el bloque c^d_i c^d_/bar{j} c_/bar{k} c_l\n",
    "def block_process_chunk(args):\n",
    "    chunk, basis, it_set = args\n",
    "    indices = []\n",
    "    values = []\n",
    "    for idx1 in chunk:\n",
    "        for idx2 in it_set:\n",
    "            i, j = int(idx1 // basis.m), int(idx1 % basis.m)\n",
    "            k, l = int(idx2 // basis.m), int(idx2 % basis.m)\n",
    "            op1 = of.FermionOperator(((2*k, 1), (2*l+1, 1)))\n",
    "            op2 = of.FermionOperator(((2*j+1, 0), (2*i, 0)))\n",
    "            mat = np.real(of.get_sparse_operator( op1 * op2, n_qubits=basis.d)[np.ix_(basis.num_ele, basis.num_ele)])\n",
    "            n_r, n_c = mat.nonzero()\n",
    "            data = mat.data\n",
    "            for r, c, v in zip(n_r, n_c, data):\n",
    "                indices.append([idx1, idx2, r, c])\n",
    "                values.append(v)\n",
    "    return indices, values\n",
    "\n",
    "def rho_2_block_gen(basis, m, num_workers=None):\n",
    "    if num_workers is None:\n",
    "        num_workers = cpu_count()  # Use all available CPUs by default\n",
    "\n",
    "    indices = []\n",
    "    values = []\n",
    "    shape = (basis.m**2, basis.m**2, basis.size, basis.size)\n",
    "\n",
    "    it_set = np.arange(basis.m**2)\n",
    "    chunks = np.array_split(it_set, num_workers)  # Split `it_set` into chunks for each worker\n",
    "\n",
    "    # Use multiprocessing Pool for parallel processing\n",
    "    with Pool(processes=num_workers) as pool:\n",
    "        # Pass arguments as tuples instead of using a lambda\n",
    "        results = list(\n",
    "            tqdm(\n",
    "                pool.imap(\n",
    "                    block_process_chunk,\n",
    "                    [(chunk, basis, it_set) for chunk in chunks]\n",
    "                ),\n",
    "                total=num_workers\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Collect results from all processes\n",
    "    for indices_chunk, values_chunk in results:\n",
    "        indices.extend(indices_chunk)\n",
    "        values.extend(values_chunk)\n",
    "\n",
    "    # Construct the sparse array\n",
    "    indices_t = np.array(indices).T\n",
    "    s_t = sparse.COO(indices_t, values, shape=shape)\n",
    "    return s_t\n",
    "\n",
    "# rho_m_gen aux func\n",
    "def process_chunk(args):\n",
    "    chunk, m_basis, basis, d, it_set = args\n",
    "    indices = []\n",
    "    values = []\n",
    "    for ii in chunk:\n",
    "        for jj in it_set:\n",
    "            # Generate the operator\n",
    "            op = m_basis.base[jj] * of.utils.hermitian_conjugated(m_basis.base[ii])\n",
    "            mat = np.real(of.get_sparse_operator(op, n_qubits=d))[np.ix_(basis.num_ele, basis.num_ele)]\n",
    "            # Extract the information\n",
    "            n_r, n_c = mat.nonzero()\n",
    "            data = mat.data\n",
    "            for r, c, v in zip(n_r, n_c, data):\n",
    "                indices.append([ii, jj, r, c])\n",
    "                values.append(v)\n",
    "    return indices, values\n",
    "\n",
    "# Parallelized rho_m_gen\n",
    "def rho_m_gen(basis, m, num_workers=None):\n",
    "    if num_workers is None:\n",
    "        num_workers = cpu_count()  # Use all available CPUs by default\n",
    "\n",
    "    indices = []\n",
    "    values = []\n",
    "    m_basis = fixed_basis(basis.d, num=m)\n",
    "    shape = (m_basis.size, m_basis.size, basis.size, basis.size)\n",
    "\n",
    "    it_set = np.arange(m_basis.size)\n",
    "    chunks = np.array_split(it_set, num_workers)  # Split `it_set` into chunks for each worker\n",
    "\n",
    "    # Use multiprocessing Pool for parallel processing\n",
    "    with Pool(processes=num_workers) as pool:\n",
    "        # Pass arguments as tuples instead of using a lambda\n",
    "        results = list(\n",
    "            tqdm(\n",
    "                pool.imap(\n",
    "                    process_chunk,\n",
    "                    [(chunk, m_basis, basis, basis.d, it_set) for chunk in chunks]\n",
    "                ),\n",
    "                total=num_workers\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Collect results from all processes\n",
    "    for indices_chunk, values_chunk in results:\n",
    "        indices.extend(indices_chunk)\n",
    "        values.extend(values_chunk)\n",
    "\n",
    "    # Construct the sparse array\n",
    "    indices_t = np.array(indices).T\n",
    "    s_t = sparse.COO(indices_t, values, shape=shape)\n",
    "    return s_t\n",
    "\n",
    "def kkbar_process_chunk(args):\n",
    "    chunk, basis, it_set = args\n",
    "    indices = []\n",
    "    values = []\n",
    "    for ii in chunk:\n",
    "        for jj in it_set:\n",
    "            ii, jj = int(ii), int(jj)\n",
    "            op1 = of.FermionOperator(((2*jj, 1), (2*jj+1, 1)))\n",
    "            op2 = of.FermionOperator(((2*ii+1, 0), (2*ii, 0)))\n",
    "            mat = np.real(of.get_sparse_operator(op1 * op2, n_qubits=basis.d)[np.ix_(basis.num_ele, basis.num_ele)])\n",
    "            n_r, n_c = mat.nonzero()\n",
    "            data = mat.data\n",
    "            for r, c, v in zip(n_r, n_c, data):\n",
    "                indices.append([ii, jj, r, c])\n",
    "                values.append(v)\n",
    "    return indices, values\n",
    "\n",
    "def rho_2_kkbar_gen(basis, num_workers=None):\n",
    "    if num_workers is None:\n",
    "        num_workers = cpu_count()  # Use all available CPUs by default\n",
    "\n",
    "    indices = []\n",
    "    values = []\n",
    "    shape = (basis.m, basis.m, basis.size, basis.size)\n",
    "\n",
    "    it_set = np.arange(basis.m)\n",
    "    chunks = np.array_split(it_set, num_workers)  # Split `it_set` into chunks for each worker\n",
    "\n",
    "    # Use multiprocessing Pool for parallel processing\n",
    "    with Pool(processes=num_workers) as pool:\n",
    "        # Pass arguments as tuples instead of using a lambda\n",
    "        results = list(\n",
    "            tqdm(\n",
    "                pool.imap(\n",
    "                    kkbar_process_chunk,\n",
    "                    [(chunk, basis, it_set) for chunk in chunks]\n",
    "                ),\n",
    "                total=num_workers\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Collect results from all processes\n",
    "    for indices_chunk, values_chunk in results:\n",
    "        indices.extend(indices_chunk)\n",
    "        values.extend(values_chunk)\n",
    "\n",
    "    # Construct the sparse array\n",
    "    indices_t = np.array(indices).T\n",
    "    s_t = sparse.COO(indices_t, values, shape=shape)\n",
    "    return s_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a756413",
   "metadata": {},
   "source": [
    "### Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75b813c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 38.84it/s]\n",
      "100%|██████████| 12/12 [00:03<00:00,  3.24it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 104.29it/s]\n",
      "100%|██████████| 12/12 [00:01<00:00,  8.86it/s]\n"
     ]
    }
   ],
   "source": [
    "d = 8\n",
    "num = d//2 # En caso de ser None, es GC\n",
    "pairs = False\n",
    "\n",
    "basis = fixed_basis(d, num=num, pairs=pairs)\n",
    "rho_1_arrays = rho_m_gen(basis, 1)\n",
    "rho_2_arrays = rho_m_gen(basis, 2)\n",
    "#rho_3_arrays = rho_m_gen(basis, 3)\n",
    "rho_2_kkbar_arrays = rho_2_kkbar_gen(basis)\n",
    "rho_2_block_arrays = rho_2_block_gen(basis, num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500e3b91",
   "metadata": {},
   "source": [
    "### New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "315fefd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ρ_1: 100%|██████████| 12/12 [00:00<00:00, 38.68it/s]\n",
      "ρ_2: 100%|██████████| 12/12 [00:03<00:00,  3.30it/s]\n",
      "ρ₂-k k̄: 100%|██████████| 12/12 [00:00<00:00, 120.24it/s]\n",
      "ρ₂-block: 100%|██████████| 12/12 [00:01<00:00,  9.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# New\n",
    "import fermionic_mbody as fmb\n",
    "basis_n = fmb.FixedBasis(d=d, num=num, pairs=pairs)\n",
    "rho_1_arrays_n = fmb.rho_m_gen(basis_n, 1)\n",
    "rho_2_arrays_n = fmb.rho_m_gen(basis_n, 2)\n",
    "#rho_3_arrays_n = fmb.rho_m_gen(basis_n, 3)\n",
    "rho_2_kkbar_arrays_n = fmb.rho_2_kkbar_gen(basis)\n",
    "rho_2_block_arrays_n = fmb.rho_2_block_gen(basis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61201126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(rho_2_block_arrays_n.todense() == rho_2_block_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c41a96b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ρ_1: 100%|██████████| 12/12 [00:00<00:00, 36.15it/s]\n",
      "ρ₂-k k̄: 100%|██████████| 12/12 [00:00<00:00, 104.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5+0.j 0.5+0.j 0.5+0.j 0.5+0.j] [0.5+0.j 0.5+0.j 0.5+0.j 0.5+0.j]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# tests/test_05_pairs_kkbar.py\n",
    "\"\"\"\n",
    "Pair-space sanity check for rho_2_kkbar_gen (pairs=True).\n",
    "\n",
    "For d = 4 (two time-reversed pairs) we prepare the equal superposition\n",
    "\n",
    "    |Ψ⟩ = (|1100⟩ + |0011⟩) / √2\n",
    "\n",
    "and verify that the **row-sums** of ρ₂_kk̄ equal the pair occupancies\n",
    "⟨n_k n_{k̄}⟩ = diag ρ₁[even indices].  This identity holds for every\n",
    "state because Σ_j c†_j c†_{j̄} is a completeness relation in the paired\n",
    "subspace.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "from fermionic_mbody import FixedBasis, rho_m, rho_m_gen, rho_2_kkbar_gen\n",
    "from tests.conftest import dense, slater_state\n",
    "\n",
    "\n",
    "def test_rho2_kkbar_row_sum_matches_rho1_diag():\n",
    "    # Basis with pair compression ON\n",
    "    basis = FixedBasis(d=8, num=4, pairs=True)  # size = 2\n",
    "\n",
    "    # |Ψ⟩  =  (|1100⟩ + |0011⟩) / √2   in *paired* space\n",
    "    vec_a = slater_state(basis, (0, 1, 2, 3))  # pair-0 occupied\n",
    "    vec_b = slater_state(basis, (4, 5, 6, 7))  # pair-1 occupied\n",
    "    psi = (vec_a + vec_b) / np.sqrt(2)\n",
    "\n",
    "    # tensors\n",
    "    rho1_t   = rho_m_gen(basis, m=1)\n",
    "    rho2kk_t = rho_2_kkbar_gen(basis)\n",
    "\n",
    "    rho1   = dense(rho_m(psi, rho1_t))        # shape (4, 4)\n",
    "    rho2kk = dense(rho_m(psi, rho2kk_t))      # shape (2, 2)\n",
    "\n",
    "    # Expected pair occupancies  ⟨n_k n_{k̄}⟩  (even indices 0,2)\n",
    "    expected = rho1[::2, ::2].diagonal()      # array([0.5, 0.5])\n",
    "\n",
    "    # Row sums must match expected occupancies\n",
    "    row_sum = rho2kk.sum(axis=1)\n",
    "    col_sum = rho2kk.sum(axis=0)\n",
    "\n",
    "    print(expected, row_sum)\n",
    "    assert np.allclose(row_sum, expected, atol=1e-8)\n",
    "    assert np.allclose(col_sum, expected, atol=1e-8)\n",
    "\n",
    "    # Matrix is Hermitian by construction\n",
    "    assert np.allclose(rho2kk, rho2kk.conj().T, atol=1e-8)\n",
    "\n",
    "test_rho2_kkbar_row_sum_matches_rho1_diag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8495e325",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ρ_1: 100%|██████████| 12/12 [00:00<00:00, 122164.19it/s]\n",
      "/home/agus/anaconda3/lib/python3.11/site-packages/sparse/_utils.py:469: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  density = np.float64(arr.nnz) / np.float64(arr.size)\n",
      "/home/agus/anaconda3/lib/python3.11/site-packages/sparse/_utils.py:487: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  f\"{np.float64(arr.nbytes) / np.float64(reduce(operator.mul, arr.shape, 1) * arr.dtype.itemsize):.2f}\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tbody><tr><th style=\"text-align: left\">Format</th><td style=\"text-align: left\">coo</td></tr><tr><th style=\"text-align: left\">Data Type</th><td style=\"text-align: left\">float64</td></tr><tr><th style=\"text-align: left\">Shape</th><td style=\"text-align: left\">(0, 0, 6, 6)</td></tr><tr><th style=\"text-align: left\">nnz</th><td style=\"text-align: left\">0</td></tr><tr><th style=\"text-align: left\">Density</th><td style=\"text-align: left\">nan</td></tr><tr><th style=\"text-align: left\">Read-only</th><td style=\"text-align: left\">True</td></tr><tr><th style=\"text-align: left\">Size</th><td style=\"text-align: left\">0</td></tr><tr><th style=\"text-align: left\">Storage ratio</th><td style=\"text-align: left\">nan</td></tr></tbody></table>"
      ],
      "text/plain": [
       "<COO: shape=(0, 0, 6, 6), dtype=float64, nnz=0, fill_value=0.0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basis = FixedBasis(d=8, num=4, pairs=True)\n",
    "rho1_t   = rho_m_gen(basis, m=1)\n",
    "rho1_t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
